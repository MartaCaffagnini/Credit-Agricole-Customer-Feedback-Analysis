{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduzione al problema e alle caratteristiche dei dati \n",
    "Per migliorare la “Customer Experience” si analizzano le risposte ai questionari Instant Feedback mediante App Crédit Agricole Italia e la rete delle relazioni tra clienti, conti correnti e filiali.\n",
    "Queste analisi hanno l'obiettivo di quantificare il grado di soddisfazione dei clienti calcolando uno score per ogni utente e la loro capacità di influenza. Infine vengono individuate le filiali che si distinguono per un maggiore gradimento negativo, o positivo. \n",
    "\n",
    "Per operare questa analisi sono stati forniti due dataset: \n",
    "\n",
    "- Dataset_1 contiene le risposte fornite dai clienti alle domande dei questionari. Ogni cliente ha il suo codice identificativo univoco (ID_CLIENTE). Ogni questionario ha il suo ID (ID_QUESTIONARIO) e il suo nome (DESC_QUESTIONARIO). Ogni questionario ha le sue specifiche domande con ID univoco (ID_DOMANDA) e testo della domanda (DESC_DOMANDA). Le risposte fornite da un cliente a un certo questionario in una certa data (DATA_COMPILAZIONE) hanno lo stesso codice ID di sessione (ID_SESSIONE_QUESTIONARIO). <br> Il campo TIPO_RISPOSTA indica il tipo di risposta alla domanda. <br> Se la risposta è chiusa a scelta singola il valore di TIPO_RISPOSTA sarà inputradio o inputmatrix; se è chiusa a scelta multipla sarà inputmulticheckb; se è una data inputdate; se aperta, cioè input testuale libero, il valore sarà inputtextarea. <br>107388 sono gli utenti che hanno risposto ad almeno un questionario. <br>23 sono i diversi questionari presenti nel dataset. <br>805943 è il numero di risposte totali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>ID_QUESTIONARIO</th>\n",
       "      <th>DESC_QUESTIONARIO</th>\n",
       "      <th>ID_SESSIONE_QUESTIONARIO</th>\n",
       "      <th>DATA_COMPILAZIONE</th>\n",
       "      <th>ID_DOMANDA</th>\n",
       "      <th>DESC_DOMANDA</th>\n",
       "      <th>TIPO_RISPOSTA</th>\n",
       "      <th>DESC_RISPOSTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6149323</td>\n",
       "      <td>17</td>\n",
       "      <td>Apertura cc online</td>\n",
       "      <td>534695</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>5275</td>\n",
       "      <td>Come sei venuto a conoscenza di Conto Crédit A...</td>\n",
       "      <td>inputradio</td>\n",
       "      <td>in-filiale-Cr-dit-agricole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6149323</td>\n",
       "      <td>17</td>\n",
       "      <td>Apertura cc online</td>\n",
       "      <td>534695</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>5276</td>\n",
       "      <td>Quanto sei soddisfatto della tua esperienza di...</td>\n",
       "      <td>inputradio</td>\n",
       "      <td>Abbastanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6149323</td>\n",
       "      <td>17</td>\n",
       "      <td>Apertura cc online</td>\n",
       "      <td>534695</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>5277</td>\n",
       "      <td>Come valuti il tempo impiegato per il processo...</td>\n",
       "      <td>inputradio</td>\n",
       "      <td>soddisfacen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENTE  ID_QUESTIONARIO   DESC_QUESTIONARIO  ID_SESSIONE_QUESTIONARIO  \\\n",
       "0     6149323               17  Apertura cc online                    534695   \n",
       "1     6149323               17  Apertura cc online                    534695   \n",
       "2     6149323               17  Apertura cc online                    534695   \n",
       "\n",
       "  DATA_COMPILAZIONE  ID_DOMANDA  \\\n",
       "0        2021-02-03        5275   \n",
       "1        2021-02-03        5276   \n",
       "2        2021-02-03        5277   \n",
       "\n",
       "                                        DESC_DOMANDA TIPO_RISPOSTA  \\\n",
       "0  Come sei venuto a conoscenza di Conto Crédit A...    inputradio   \n",
       "1  Quanto sei soddisfatto della tua esperienza di...    inputradio   \n",
       "2  Come valuti il tempo impiegato per il processo...    inputradio   \n",
       "\n",
       "                DESC_RISPOSTA  \n",
       "0  in-filiale-Cr-dit-agricole  \n",
       "1                  Abbastanza  \n",
       "2                 soddisfacen  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importazione delle librerie necessarie\n",
    "import pandas as pd \n",
    "#inseriamo il primo dataset in un dataframe con dtype specifichiamo i tipi dei valori di ogni colonna\n",
    "dataset = pd.read_csv('Dataset1_Risposte_Questionari.txt', sep=\"\\t\", header=0,dtype = {'ID_CLIENTE': int,\n",
    "                                                                                       'ID_QUESTIONARIO': int, \n",
    "                                                                                       'DESC_QUESTIONARIO': str,\n",
    "                                                                                       'ID_SESSIONE_QUESTIONARIO': int, \n",
    "                                                                                       'DATA_COMPILAZIONE': str, \n",
    "                                                                                       'ID_DOMANDA': int, \n",
    "                                                                                       'DESC_DOMANDA': str, \n",
    "                                                                                       'TIPO_RISPOSTA': str,\n",
    "                                                                                       'DESC_RISPOSTA': str})\n",
    "dataset.head(3) #mostriamo le prime righe del dataset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset_2 contiene i collegamenti tra coppie di clienti (ID_CLIENTE_1, ID_CLIENTE_2). <br>\n",
    "Ciascun cliente ha un campo in cui è indicato il suo id, la sua Natura Giuridica (PF = persona fisica, COI=cointestazione, DI=Ditta Individuale), e l'ID della sua filiale (ID_FILIALE). La tipologia dei collegamenti tra due clienti è individuata dal campo COD_COLLEGAMENTO e descritta da DESC_COLLEGAMENTO. <br>I clienti sono 3505346 e le relazioni che intercorrono sono in totale 4089536."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>COD_NATURA_GIURIDICA_1</th>\n",
       "      <th>ID_FILIALE_1</th>\n",
       "      <th>COD_COLLEGAMENTO</th>\n",
       "      <th>DESC_COLLEGAMENTO</th>\n",
       "      <th>ID_CLIENTE_2</th>\n",
       "      <th>COD_NATURA_GIURIDICA_2</th>\n",
       "      <th>ID_FILIALE_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6123972</td>\n",
       "      <td>DI</td>\n",
       "      <td>28438</td>\n",
       "      <td>R01</td>\n",
       "      <td>TIT. DITTA INDIV.</td>\n",
       "      <td>6482323</td>\n",
       "      <td>PF</td>\n",
       "      <td>28438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6123981</td>\n",
       "      <td>DI</td>\n",
       "      <td>28638</td>\n",
       "      <td>R01</td>\n",
       "      <td>TIT. DITTA INDIV.</td>\n",
       "      <td>6173394</td>\n",
       "      <td>PF</td>\n",
       "      <td>28638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6123989</td>\n",
       "      <td>PF</td>\n",
       "      <td>45955</td>\n",
       "      <td>I85</td>\n",
       "      <td>HA COME EREDE</td>\n",
       "      <td>6756182</td>\n",
       "      <td>PF</td>\n",
       "      <td>45955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENTE COD_NATURA_GIURIDICA_1  ID_FILIALE_1 COD_COLLEGAMENTO  \\\n",
       "0     6123972                     DI         28438              R01   \n",
       "1     6123981                     DI         28638              R01   \n",
       "2     6123989                     PF         45955              I85   \n",
       "\n",
       "   DESC_COLLEGAMENTO  ID_CLIENTE_2 COD_NATURA_GIURIDICA_2  ID_FILIALE_2  \n",
       "0  TIT. DITTA INDIV.       6482323                     PF         28438  \n",
       "1  TIT. DITTA INDIV.       6173394                     PF         28638  \n",
       "2      HA COME EREDE       6756182                     PF         45955  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inseriamo il secondo dataset in un dataframe\n",
    "dataset2 = pd.read_csv('Dataset2_Collegamenti_Clienti.txt', sep=\"\\t\", header=0,dtype = {'ID_CLIENTE': int,\n",
    "                                                                                       'COD_NATURA_GIURIDICA_1': str, \n",
    "                                                                                       'ID_FILIALE_1': int,\n",
    "                                                                                       'COD_COLLEGAMENTO': str, \n",
    "                                                                                       'DESC_COLLEGAMENTO': str, \n",
    "                                                                                       'ID_CLIENTE_2': int, \n",
    "                                                                                       'COD_NATURA_GIURIDICA_2': str, \n",
    "                                                                                       'ID_FILIALE_2': int})\n",
    "#specifichiamo il tipo di ogni campo perchè nel dataset valori della stessa␣\n",
    "#colonna sono di tipo diverso \n",
    "dataset2.head(3) #mostriamo le prime righe del dataset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrizione approccio risolutivo adottato\n",
    "\n",
    "Parte 1\n",
    "\n",
    "Per calcolare lo score di ogni cliente viene effettuata l'analisi di risposte chiuse e risposte aperte contenute nel Dataset_1. <br>\n",
    "Dopo aver eliminato le domande non rilevanti per il calcolo di soddisfazione, a ogni risposta chiusa viene associato un certo score definito in modo statico e arbitrario. Verrà così aggiunta una colonna al dataset con lo score corrispondente a ogni riga, cioè a ogni risposta. Le categorie di classificazione saranno 4: -1.0, -0.5, 0.5, 1. <br>\n",
    "Per quanto riguarda le risposte aperte viene assegnato uno score facendo la media degli score delle risposte chiuse dello stesso questionario del singolo cliente. <br>\n",
    "Poi viene proposta una Sentiment Analysis creando un modello di Machine Learning per classificare le risposte come feedback negativi o positivi. Per l'addestramento del modello i target utilizzati sono gli score calcolati basandosi sulle risposte chiuse. <br>\n",
    "\n",
    "Prima di creare il modello viene applicata una fase di preprocessing sulle risposte aperte per aiutare il modello ad apprendere meglio dai dati. Questo preprocessing comprende il tokenizing del testo, eliminazione della punteggiatura, delle stopword e delle parole grammaticalmente errate. <br>\n",
    "\n",
    "I modelli creati sono basati sul classificatore Bernoulli Naive Bayes, oppure il classificatore multinomiale Naive Bayes, o Complement Naive Bayes, infine Random forest. <br>\n",
    "Una volta addestrati e validati i modelli, viene individuato quello con l'accuratezza migliore. <br> <br>\n",
    "\n",
    "Ora che si hanno gli score per ogni risposta contenuta nel dataset si può calcolare lo score di soddisfazione di ciascun cliente. Prima si raggruppano le risposte date da ciascun cliente basandosi sul suo ID e poi si calcola la media degli score. A ogni cliente ora è associato uno score di soddisfazione.\n",
    "Ordinando i clienti in base al loro score si possono individuare i clienti più soddisfatti e i più insoddisfatti.\n",
    "\n",
    "Parte 2\n",
    "\n",
    "Vengono preparati i file csv per importare i dati in un grafo Neo4j.\n",
    "Per calcolare il sottografo di un cliente viene utilizzato l'algoritmo Dijkstra Single-Source, algoritmo di path finding. Questo algoritmo trova i nodi connessi al nodo sorgente e il percorso più breve per raggiungerli. Per calcolare il grado di influenza di ogni nodo del sottografo si prende lo score del nodo sorgente e lo si divide per la lunghezza del percorso che collega il cliente al nodo sorgente. Il grado di influenza prende il segno dallo score del cliente influenzato dal nodo sorgente.\n",
    "\n",
    "L'approccio alternativo proposto prevede l'utilizzo dell'algoritmo WCC (Weakly Connected Components). Questo algoritmo divide i nodi in gruppi.  Nel calcolo del grado di influenza viene sempre usato l'algoritmo Dijkstra Single-Source ma come lunghezza del percorso non viene considerato il numero di archi che separano due nodi, ma il costo delle relazioni che devono essere attraversate.\n",
    "Dopo aver individuato i clienti più soddisfatti e meno soddisfatti in base al loro score, viene calcolato il loro sottografo di influenza.\n",
    "\n",
    "Per ogni nodo con uno score viene calcolato il suo sottografo di clienti e sui nodi influenzati si scrive il grado di influenza. Se un cliente è influenzato da più nodi, le influenze vengono sommate e poi divise per il numero di nodi da cui è stato influenzato. Per avere un numero che rappresenta la soddisfazione del cliente, si somma lo score al grado di influenza. Questo viene riportato nell'intervallo -1, 1.\n",
    "Ora si ha a disposizione il grado di soddisfazione dei clienti. Per calcolare il numero di clienti di ogni filiale che hanno la property soddisfazione, si utilizza l'algoritmo Degree Centrality che calcola gli archi uscenti da ogni nodo.\n",
    "Per calcolare il livello di soddisfazione di ogni filiale viene fatta una media di soddisfazione considerando tutti i clienti che ne hanno espressa una.\n",
    "Dopo aver assegnato un valore di soddisfazione a ogni filiale vengono individuate le 3 più virtuose e le 3 più critiche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analytics\n",
    "\n",
    "Per calcolare uno score di soddisfazione per ciascun cliente sono necessarie tecniche di text classification da applicare alle risposte fornite da ciascun utente. \n",
    "\n",
    "Prima di utilizzare questi dati è necessaria una prima fase di data-cleaning. <br>\n",
    "Sono state individuate ed eliminate le domande con risposte non utili o domande non rilevanti per il calcolo del grado di soddisfazione dei clienti. \n",
    "\n",
    "Sono state eliminate le risposte nulle oppure risposte che contenevano solo un segno di punteggiatura. <br>\n",
    "Due domande sono state inserite in un nuovo questionario per tenere separato il feedback di quell'argomento e facilitare l'analisi successiva. <br>\n",
    "Infine alcune risposte chiuse sono state sostituite con altre per riunire risposte che hanno lo stesso significato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in una lista inseriamo le domande non utili per valutare il livello di soddisfazione dei clienti\n",
    "domande_eliminare=['Come sei venuto a conoscenza di Conto Crédit Agricole?',\n",
    "     'Cosa ti aspetti dal tuo nuovo conto?',\n",
    "     'Cosa ti ha spinto ad aprire Conto Crédit Agricole?',\n",
    "     'Cosa ti ha spinto a scegliere Mutuo Agricole',\n",
    "     'Desideri essere ricontattato?',\n",
    "     'Cosa ti spinge a utilizzare la funionalità bonifico istantaneo?',\n",
    "     'Come hai conosciuto questo servizio?',\n",
    "     'Conosci la funzionalità Instant Payment per inviare denaro in tempo reale?',\n",
    "     'Quante volte sei stato contattato dal tuo Gestore negli ultimi 6 mesi?',\n",
    "     'Solitamente, quale canale utilizzi per le tue operazioni bancarie?',\n",
    "     'Come sei venuto a conoscenza di mutuo Crédit Agricole?',\n",
    "     \"Quali tra i seguenti servizi/vantaggi vorresti completassero l'offerta di Mutuo CA?\",\n",
    "     'Qual è il tuo titolo di studio?',\n",
    "     'Quale modalità hai utilizzato per effettuare il bonifico?',\n",
    "     'Come sei venuto a conoscenza del Prestito Crédit Agricole?',\n",
    "     'Altro_fonticomunicazione',\n",
    "     'Desideri essere ricontattato?_1',\n",
    "     'Cosa ti ha spinto a scegliere il Prestito Agos Credit Agricole?',\n",
    "     'Come sei venuto a conoscenza della polizza?',\n",
    "     'Cosa ti ha spinto ad acquistare una polizza assicurativa Crédit Agricole?',\n",
    "     'Quale tra le seguenti modalità',\n",
    "     'Polizze online', \n",
    "     'Quale tra le seguenti modalità Preventivo',\n",
    "     'Altro_apprezzati',\n",
    "     'A che punto sei del tuo percorso universitario?',\n",
    "     'Stai svolgendo qualche attività lavorativa?',\n",
    "     'Come hai attivato la tua Student Card?',\n",
    "     'Quali sono i tuoi progetti o i tuoi bisogni?',\n",
    "     'Che studente sei?',\n",
    "     'Data di laurea?',\n",
    "     'Argomenti preferiti_1',\n",
    "     'Altro_argomentipreferiti',\n",
    "     'Si',\n",
    "     'No',\n",
    "     'Quanto utilizzi la tua Student Card',\n",
    "     'A che punto sei del tuo percorso universitario?',\n",
    "     'Quali iniziative, in accordo con l’Ateneo, ti potrebbero interessare per il futuro?',\n",
    "     'Quando ha manifestato la volontà di estinguere il mutuo, quali soluzioni/proposte le sono state offerte dal suo gestore',\n",
    "     'Fra quelli elencati di seguito, qual è il motivo per cui ha estinto il mutuo',\n",
    "     'Ha provato a chiedere una rinegoziazione delle condizioni del mutuo',\n",
    "     'Hai già utilizzato l’App di Crédit Agricole',\n",
    "     'Utilizzerai l’App o l’Home Banking per fare il tuo prossimo pagamento? (Es. bonifico, ricarica, operazione di compravendita sui mercati, ecc..)',\n",
    "     'Userai l’App per le tue prossime operazioni?',\n",
    "     'Altro_2',\n",
    "     'Altro2', \n",
    "     'Altro3'  ,\n",
    "     'Qual è il principale aspetto che cambieresti per migliorare l’esperienza?',\n",
    "     'Qual è il principale aspetto che cambieresti per migliorare la tua esperienza?',\n",
    "     'Argomentazione_soddisfatti',\n",
    "     'Argomentazione_insoddisfatti_1',\n",
    "     'Puoi argomentare la tua valutazione?_positivi',\n",
    "     'Puoi argomentare la tua valutazione?_negativi',\n",
    "     'Può argomentare la sua valutazione_POS',\n",
    "     'Qual è l’aspetto che hai maggiormente apprezzato?',\n",
    "     'Visualizzare e firmare in digitale i documenti relativi all’operazione che ha concluso tramite «CA per Te - la Consulenza Dinamica» è stato',\n",
    "     \"Qual è l'aspetto che hai maggiormente apprezzato?\",\n",
    "     'Per quali motivi ti ritieni soddisfatto della tua Filiale',\n",
    "     'Per quali motivi non ti ritieni soddisfatto della tua Filiale?',\n",
    "     'Puoi motivare la tua scelta?'          \n",
    "] \n",
    "\n",
    "#eliminiamo le domande contenute nella lista e inseriamo le rimanenti nel dataframe df\n",
    "df = dataset[dataset['DESC_DOMANDA'].isin(domande_eliminare)==False]\n",
    "\n",
    "#domande aperte da eliminare perchè non hanno risposte utili all'analisi:\n",
    "df=df.loc[df['ID_DOMANDA']!=6275]\n",
    "df=df.loc[df['ID_DOMANDA']!=7307]\n",
    "df=df.loc[df['ID_DOMANDA']!=7310]\n",
    "df=df.loc[df['ID_DOMANDA']!=7778]\n",
    "df=df.loc[df['ID_DOMANDA']!=17500]\n",
    "df=df.loc[df['ID_DOMANDA']!=12277]\n",
    "df=df.loc[df['ID_DOMANDA']!=7574]\n",
    "\n",
    "df=df.loc[df['ID_QUESTIONARIO']!=60] #eliminare questionario 60 \n",
    "\n",
    "df=df.dropna() #eliminare tutti i valori nan \n",
    "df=df.loc[df['DESC_RISPOSTA']!='.'] #eliminare risposte con solo '.'\n",
    "df=df.loc[df['DESC_RISPOSTA']!='?'] #eliminare risposte con solo '?'\n",
    "df=df.loc[df['DESC_RISPOSTA']!='!'] #eliminare risposte con solo '!'\n",
    "\n",
    "#eliminare le risposte 'No' alla domanda 'puoi argomentare'\n",
    "y=df.loc[df['DESC_DOMANDA']=='Puoi argomentare questa tua valutazione?' ]\n",
    "df=df.drop(y.loc[y['DESC_RISPOSTA']=='No'].index)\n",
    "\n",
    "#aggiungere un questionario con solo le due domande  8273, 8274\n",
    "df.loc[df['ID_DOMANDA']==8273, ['ID_QUESTIONARIO']]= 29\n",
    "df.loc[df['ID_DOMANDA']==8274, ['ID_QUESTIONARIO']]= 29\n",
    "\n",
    "#sostituiamo le stringhe passate come primo parametro alla funzione replace con il secondo argomento.\n",
    "df=df.replace('Per-niente', 'perniente')\n",
    "df=df.replace('Perniente', 'perniente')\n",
    "df=df.replace('Poco', 'poco')\n",
    "df=df.replace('pocoutile', 'poco')\n",
    "df=df.replace('abbastanzau', 'abbastanza')\n",
    "df=df.replace('Abbastanza', 'abbastanza')\n",
    "df=df.replace('soddisfacen', 'soddisfacente')\n",
    "df=df.replace('nonadeguata', 'nonadeguato')\n",
    "df=df.replace('Molto', 'molto')\n",
    "df=df.replace('nonintuitiva', 'nonintuitivo')\n",
    "df=df.replace('complessa', 'complesso')\n",
    "df=df.replace('lenta', 'lento')\n",
    "df=df.replace('intuitiva', 'intuitivo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel dataframe 'chiuse' vengono inserite le risposte chiuse del tipo 'inputradio'. <br>\n",
    "Per ogni riga del dataframe viene calcolato uno score che viene inserito in una lista che costituirà la nuova colonna inserita nel dataframe. <br>\n",
    "Dopo un'analisi delle risposte sono state individuate 4 classi adatte alla classificazione delle stesse. <br>\n",
    "Alle risposte del tipo 'Per niente', 'eccessivo', 'no', 'v0', 'v1', 'v2' è stato associato il punteggio più basso: -1. <br>\n",
    "Se la risposta è 'poco', 'non adeguato', 'difficoltosa, 'v3', 'v4', 'v5' lo score è -0.5. <br>\n",
    "0.5 è assegnato alle risposte come 'abbastanza, 'soddisfacente', 'v6', 'v7', 'v8'. <br>\n",
    "Il punteggio massimo (1.0) è associato a 'molto', 'eccellente', 'si', 'v9', 'v10'. <br> \n",
    "\n",
    "Lo stesso procedimento viene applicato alle domande con risposta multipla. <br>\n",
    "Nel dataframe non è presente neanche una domanda del tipo 'inputmatrix'. <br>\n",
    "Alle risposte 'altro' viene assegnato un punteggio 0 e poi verranno eliminate perchè 'altro' verrà esplicitato in una domanda aperta che verrà valutata quindi non è necessario assegnare uno score a questa risposta. <br>\n",
    "Il valore 2 viene assegnato a risposte che non sono inserite nella classificazione perchè non esprimono un giudizio. Anche queste risposte verranno eliminate. <br> \n",
    "\n",
    "Una volta assegnato lo score a ogni domanda con risposta chiusa, viene creato un dataframe domande_chiuse che unisce tutte queste risposte e verrà utilizzato per calcolare i target delle risposte aperte necessari per l'addestramento del modello. \n",
    "\n",
    "Prima di utilizzare il dataframe ottenuto, vengono eliminate le domande chiuse non utili per il calcolo del target della domanda aperta perchè esprimono pareri su argomenti diversi pur facendo parte dello stesso questionario. <br>\n",
    "Nel dataframe 'medie' viene calcolato lo score di soddisfazione medio su ogni questionario della specifica sessione dello specifico cliente. Lo score di ogni riga verrà associato a ogni risposta aperta con il corrispondente id questionario, id sessione e id cliente. \n",
    "\n",
    "Nel dataframe 'aperte' vengono inserite tutte le risposte aperte a cui andrà associato il corrispondente score. <br>\n",
    "Per ogni riga di 'aperte' viene selezionato lo score in 'medie' associato a specifico cliente, dello specifico questionario, della specifica sessione. <br>\n",
    "Poi la colonna degli score viene inserita in 'aperte'. <br>\n",
    "Dato che i valori di score sono valori continui, questi devono essere etichettati in due classi: positivi (1.0) e negativi (-1.0). Gli score minori a 0.0 sono classificati come negativi e quelli superiori o uguali a 0.0 come positivi.  <br>\n",
    "\n",
    "Il dataset di training e testing è ora disponibile. <br>\n",
    "Nel dataframe samples vengono inserite solo le colonne con la risposta aperta e lo score associato. <br>\n",
    "In questo modo si ha il text (la domanda aperta) e la label (lo score).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>ID_QUESTIONARIO</th>\n",
       "      <th>ID_SESSIONE_QUESTIONARIO</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6124029</td>\n",
       "      <td>29</td>\n",
       "      <td>35306</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6124029</td>\n",
       "      <td>37</td>\n",
       "      <td>35306</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6124029</td>\n",
       "      <td>51</td>\n",
       "      <td>820916</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6124174</td>\n",
       "      <td>58</td>\n",
       "      <td>577474</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6124554</td>\n",
       "      <td>29</td>\n",
       "      <td>187631</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENTE  ID_QUESTIONARIO  ID_SESSIONE_QUESTIONARIO  SCORE\n",
       "0     6124029               29                     35306   1.00\n",
       "1     6124029               37                     35306   0.83\n",
       "2     6124029               51                    820916  -0.17\n",
       "3     6124174               58                    577474   0.50\n",
       "4     6124554               29                    187631   1.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inserite le risposte del tipo 'inputradio' nel dataframe chiuse\n",
    "chiuse=df.loc[(df['TIPO_RISPOSTA']=='inputradio')]\n",
    "new_col=[]\n",
    "i=0\n",
    "for utente in chiuse['ID_CLIENTE']:\n",
    "    riga=chiuse.iloc[i][:]\n",
    "    #per ogni risposta viene assegnato lo score corrispondente\n",
    "    if((riga[8]=='perniente') |( riga[8]=='eccessivo') |(riga[8]=='no' )| (riga[8]=='v0')|(riga[8]=='v1')| (riga[8]=='v2') ): \n",
    "         new_col.append(-1.0)\n",
    "    elif ((riga[8]=='poco') |( riga[8]=='nonadeguato')|( riga[8]=='difficoltosa')|(riga[8]=='v3' )|(riga[8]=='v4' )| (riga[8]=='v5' )):\n",
    "         new_col.append(-0.5)\n",
    "    elif ((riga[8]=='abbastanza') |( riga[8]=='soddisfacente') |(riga[8]=='v6' )|(riga[8]=='v7' )| (riga[8]=='v8' )):\n",
    "         new_col.append(0.5)\n",
    "    elif ((riga[8]=='molto') |( riga[8]=='eccellente') |( riga[8]=='si')|(riga[8]=='v9' )| (riga[8]=='v10' ) ):\n",
    "         new_col.append(1)\n",
    "    i=i+1\n",
    "    \n",
    "chiuse.insert(9,'SCORE',new_col) #inseriamo la nuova colonna nel dataframe 'chiuse'\n",
    "\n",
    "#mettiamo nel dataframe chiuse_multiple le risposte del tipo 'inputmulticheckb'\n",
    "chiuse_multiple=df.loc[(df['TIPO_RISPOSTA']=='inputmulticheckb')]\n",
    "new_col_2=[]\n",
    "i=0\n",
    "for utente in chiuse_multiple['ID_CLIENTE']:\n",
    "    riga=chiuse_multiple.iloc[i][:]\n",
    "    #per ogni risposta viene assegnato uno score che viene memorizzato in new_col_2\n",
    "    if((riga[8]=='lento') |( riga[8]=='complicato') |(riga[8]=='nonintuitivo' )| \n",
    "       (riga[8]=='complesso')| (riga[8]=='lento')\n",
    "       |(riga[8]=='problematichedisservizi')\n",
    "       |(riga[8]=='relazioneinsoddisfacenteconilgestorebanca') \n",
    "       |(riga[8]=='offertadinuoviprodottinonadeguataalleesigenze') \n",
    "       | (riga[8]=='servizipocoinnovativi')): \n",
    "        new_col_2.append(-1.0)\n",
    "    elif ((riga[8]=='comodo') |( riga[8]=='veloce') |( riga[8]=='semplice')|(riga[8]=='sicuro' )|\n",
    "          (riga[8]=='intuitivo' )|(riga[8]=='aperturaaltrocontocrditagricole')):\n",
    "         new_col_2.append(1)\n",
    "    elif ((riga[8]=='altro')):\n",
    "        new_col_2.append(0)\n",
    "    else:\n",
    "          new_col_2.append(2)\n",
    "    \n",
    "    i=i+1\n",
    "    \n",
    "chiuse_multiple.insert(9,'SCORE',new_col_2) #inseriamo la colonna nel dataframe \n",
    "chiuse_multiple = chiuse_multiple[chiuse_multiple['SCORE']!=2] #eliminiamo le risposte con score 2\n",
    "chiuse_multiple = chiuse_multiple[chiuse_multiple['SCORE']!=0] #eliminiamo le risposte con score 0\n",
    "\n",
    "#uniti i due gruppi di domande chiuse uno sotto l'altro\n",
    "domande_chiuse=pd.merge(left=chiuse, right=chiuse_multiple,how='outer') # ogni risposta chiusa ha il corrispondente score\n",
    "\n",
    "#eliminare domande chiuse non utili per il calcolo dei target\n",
    "domande_chiuse=domande_chiuse.loc[domande_chiuse['ID_DOMANDA']!=18429]\n",
    "domande_chiuse=domande_chiuse.loc[domande_chiuse['ID_DOMANDA']!=8219]\n",
    "domande_chiuse=domande_chiuse.loc[domande_chiuse['ID_DOMANDA']!=16206]\n",
    "domande_chiuse=domande_chiuse.loc[domande_chiuse['ID_DOMANDA']!=13766]\n",
    "domande_chiuse=domande_chiuse.loc[domande_chiuse['ID_DOMANDA']!=19282]\n",
    "\n",
    "#raggruppo le domande sul campo dell'utente, sull'id del questionario e id della sessione. Dopo il raggruppamento viene \n",
    "#fatta la media sul campo score (colonna 9)\n",
    "medie=domande_chiuse.groupby(['ID_CLIENTE','ID_QUESTIONARIO','ID_SESSIONE_QUESTIONARIO'])['SCORE'].mean()\n",
    "medie=medie.reset_index() # reset degli indici\n",
    "medie['SCORE']=medie['SCORE'].round(2) # arrotondamento degli score a due cifre dopo la virgola\n",
    "medie.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>DESC_RISPOSTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ho avuto bisogno di aiuto in agenzia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Facile per accedere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Serietà e Professionalità</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SCORE                         DESC_RISPOSTA\n",
       "5     1.0  Ho avuto bisogno di aiuto in agenzia\n",
       "23    1.0                   Facile per accedere\n",
       "29    1.0             Serietà e Professionalità"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selezione di tutte le domande a risposta aperta\n",
    "aperte=df.loc[(df['TIPO_RISPOSTA']=='inputtextarea')] \n",
    "\n",
    "new_col_3=[] #lista in cui verranno inseriti i nuovi valori di colonna\n",
    "i=0\n",
    "for utente in aperte['ID_CLIENTE']: #iterazione su tutte le righe di aperte\n",
    "    riga=aperte.iloc[i][:] # selezione della riga di aperte a cui associamo lo score esatto\n",
    "    id_quest=riga[1] #prendiamo il valore del questionario\n",
    "    id_sessione=riga[3] #valore della sessione\n",
    "    domande_rif=medie.loc[(medie['ID_CLIENTE']==utente)\n",
    "                          &(medie['ID_QUESTIONARIO']==id_quest)\n",
    "                          &(medie['ID_SESSIONE_QUESTIONARIO']==id_sessione)]\n",
    "    #selezione in medie del della riga con specifico id cliente, id questionario e id sessione\n",
    "    media=domande_rif['SCORE'] # score da associare\n",
    "    media=media.to_string(index=False) # conversione a stringa\n",
    "    new_col_3.append(media) #inserimento del valore nella lista\n",
    "    i=i+1\n",
    "\n",
    "aperte.insert(9,'SCORE',new_col_3) #colonna inserita \n",
    "aperte['SCORE']=aperte['SCORE'].astype(float) #conversione dei valori in float\n",
    "aperte.loc[aperte['SCORE']<0.0,['SCORE']]=-1 #score minori a 0.0 diventano uguali a -1\n",
    "aperte.loc[aperte['SCORE']>=0.0,['SCORE']]=1 #score maggiori o uguali di 0.0 diventano uguali a 1.\n",
    "cols = ['SCORE','DESC_RISPOSTA']\n",
    "samples = aperte[cols]\n",
    "samples.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di utilizzare il dataset per l'addestramento del modello, si applica una fase di preprocessing sulle risposte aperte per aiutare il modello ad apprendere meglio dai dati.\n",
    "\n",
    "- Viene fatto il tokenizing del testo. La tokenizzazione è una tecnica utilizzata per suddividere un testo in unità più piccole, come singole parole o termini chiamate token. In questo progetto è stato utilizzato sent_tokenize, cioè un Tokenizer (fornito dal modulo nltk) che mantiene intatte le frasi. Le frasi o parole tokenizzate possono essere trasformate in dataframe e vettorizzate. \n",
    "\n",
    "- Viene eliminata la punteggiatura e le stopword. Vengono cancellate tutte quelle informazioni che non portano ad una maggior informazione, ma al contrario aggiungono solamente rumore. \n",
    "\n",
    "- Eliminare le parole grammaticalmente errate. Utilizzando un file txt con una raccolta delle parole in lingua italiana, sono state eliminate le parole che non risultavano in quell'elenco.\n",
    "\n",
    "- Stemming: un algoritmo che elimina i suffissi delle parole per raggruppare parole che hanno stesso significato, ma suffisso diverso come verbi coniugati oppure parole al femminile o maschile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importate le librerie necessarie al preprocessing\n",
    "from string import punctuation\n",
    "import os\n",
    "import nltk as nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenize =sent_tokenize #in tokenize viene messa la sent_tokenize\n",
    "\n",
    "stemmer=nltk.stem.snowball.ItalianStemmer()\n",
    "\n",
    "#memorizziamo in una variabile l'insieme delle congiunzioni italiane\n",
    "italian_stopwords = set(stopwords.words('italian'))\n",
    "\n",
    "#lettura del file con tutte le parole italiane. Tutte le parole contenute del file vengono memorizzate in un insieme\n",
    "all_italian_words = set(word.replace(\"\\n\", \"\") for word in open(\"italian_words.txt\").readlines())\n",
    "\n",
    "#funzione per tokenizzare un testo. \n",
    "def get_tokenized_text(text):\n",
    "    return \" \".join(tokenize(text)) \n",
    "    #la funzione join() unisce elementi iterabili come una lista e restituisce una stringa concatenata come output\n",
    "\n",
    "def get_text_stemmed(text):\n",
    "    return \" \".join([stemmer.stem(w) for w in text.split()])\n",
    "\n",
    "#funzione che elimina le congiunzioni\n",
    "def get_text_without_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in italian_stopwords]) \n",
    "    #se la parola contenuta in text non fa parte di italian_stopwords questa non viene aggiunta \n",
    "\n",
    "#funzione che rimuove la punteggiatura\n",
    "def get_text_without_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', punctuation)) \n",
    "    #come terzo parametro di maketrans viene passata la lista di caratteri che devono essere eliminati\n",
    "\n",
    "#funzione che rimuove le parole scritte in modo errato\n",
    "def get_text_without_uncorrect_words(text):\n",
    "    return \" \".join([word for word in text.split() if word in all_italian_words]) \n",
    "    #word deve essere contenuto in all_italian_words, altrimenti viene eliminata\n",
    "      \n",
    "    \n",
    "def get_normalized_text(text):\n",
    "    text = get_tokenized_text(text) #testo viene tokenizzato\n",
    "    text = get_text_without_stopwords(text) #eliminazione stopwords\n",
    "    text = get_text_without_punctuation(text) #eliminazione punteggiatura\n",
    "    text = get_text_without_uncorrect_words(text) #eliminazione parole scritte in modo scorretto\n",
    "    text = get_text_stemmed(text) #stemming del testo\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_label(sample):\n",
    "    return sample[0] #restituisce la lable di sample\n",
    "\n",
    "\n",
    "def get_text(sample):\n",
    "    return sample[1].lower() #ogni lettera della risposta viene trasformata in lower case e restituisce text di sample\n",
    "\n",
    "\n",
    "def preprocess_samples(samples):\n",
    "    samples = samples.values.tolist() #valori di samples trasformati in una lista\n",
    "\n",
    "    #per ogni sample prendiamo la label e il testo che viene normalizzato\n",
    "    normalized_samples = [(get_label(sample), get_normalized_text(get_text(sample))) for sample in samples]\n",
    "\n",
    "    #eliminiamo i sample con testo vuoto\n",
    "    normalized_samples = [sample for sample in normalized_samples if get_text(sample) != \"\"]\n",
    "    \n",
    "    #creiamo dataframe con una colonna label e una text\n",
    "    normalized_samples = pd.DataFrame(set(normalized_samples), columns=[\"label\", \"text\"])\n",
    "    \n",
    "    return normalized_samples\n",
    "    \n",
    "#preprocess\n",
    "samples=preprocess_samples(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction \n",
    "Con Feature Extraction possiamo indicare\n",
    "tutte quelle tecniche che a partire da un testo hanno l’obiettivo di trasformarlo in un insieme\n",
    "di feature che possono essere utilizzate da un algoritmo. Più nel dettaglio possiamo dire che\n",
    "queste tecniche dato un testo, lo trasformano in una tabella (chiamata bag of words o Bow)\n",
    "con la quale ogni parola di questo testo (ora diventata una feature) è associata ad un valore\n",
    "numerico. Questa bag of words, alla fine di questo processo non sarà altro che il nostro nuovo\n",
    "dataset. \n",
    "\n",
    "## TfidfVectorizer \n",
    "All’interno di questo progetto è stato utilizzato un Tf-idf Vectorizer, un algoritmo che trasforma il testo in una bag of word ma con un criterio un po’ diverso da un semplice Countvectorizer. <br>\n",
    "\n",
    "Un TfidfVectorizer produce comunque una bag of words, ma i valori presenti all’interno di essa non sono solo valori dicotomici ma sono generati calcolando il Tf (Term frequency) della parola e moltiplicandolo per l’Idf (Inverse document frequency) del documento. <br>\n",
    "\n",
    "Il Term frequency indica quante volte una certa parola è presente in un testo. <br>\n",
    "L’Inverse Document frequency ed indica l’inverso della Df (Document frequency) cioè il numero di documenti dove appare una determinata parola. <br>\n",
    "Idf = log (1/Df) con Df = #{testo : testi | parola ∈ testo} <br>\n",
    "Il Tfidf è direttamente proporzionale al numero di volte che una parola è presente in una frase ed inversamente proporzionale a quanti documenti contengono quella parola. Una parola con un TfIdf alto è una parola che ha molto più\n",
    "peso rispetto alle altre. \n",
    "\n",
    "## N-grammi \n",
    "Gli n-grammi sono sottesequenze di una sequenza, che nel nostro caso è il testo della risposta; un trigramma è un n-gramma\n",
    "formato da 3 elementi/parole. <br>\n",
    "Tutte le parole di tutte le risposte del dataset vanno a formare gli attributi (le feature, i valori nelle colonne) della nostra bag of words, ma c’è la possibilità di \"settare\" come feature anche tutti gli n-grammi dei documenti di un dataset, con il fine di cercare di aumentare l’accuratezza e la qualità del nostro modello. <br>\n",
    "Nel modello utilizzato i migliori risultati sono stati ottenuti con n=4.\n",
    "\n",
    "## Feature Selection\n",
    "La Feature Selection è un processo che prevede di selezionare solo una parte più o meno ampia delle features a nostra disposizione per migliorare l'efficienza ed eliminare feature \"rumorose\" che non portano grandi informazioni aggiuntive.\n",
    "\n",
    "Dopo test empirici le feature selezionate per il modello impiegato sono le 113000 feature più importanti, cioè le 113000 feature che hanno ottenuto lo \"score\" più alto con la funzione di score f_classif (basata sull’ANOVA, Analysis of Variance, ed utilizzabile solo per variabili categoriche)\n",
    "\n",
    "\n",
    "## Addestramento\n",
    "Per addestrare il modello, il dataset è stato suddiviso in train/test, rispettivamente 80%/20% delle risposte. \n",
    "Gli algoritmi forniti da sklearn (e le loro accuratezze) provati per l’addestramento\n",
    "sono i seguenti: <br>\n",
    "\n",
    "Multinomial Bayes: 85.01 % <br>\n",
    "BernoulliNB:  88.89 % % <br>\n",
    "Complement Bayes: 76.8 % <br>\n",
    "RandomForestClassifier: 85.01 % <br>\n",
    "\n",
    "\n",
    "BernoulliNB è adatto per feature booleane o binarie quindi è perfetto per il problema. <br>\n",
    "\n",
    "Il classificatore multinomiale Naive Bayes classifier è adatto alla classificazione con valori di feature discreti (ad esempio il conteggio di parole per la text classification). <br>\n",
    "\n",
    "Il classificatore Complement Naive Bayes è stato ideato per correggere assunzioni gravi fatte dal classificatore standard Multinomial Naive Bayes. Inoltre è particolarmente adatto a dataset non bilanciati. <br>\n",
    "\n",
    "Random forest crea un insieme di alberi di decisione su vari sottoinsiemi del dataset e riduce l'overfitting. La dimensione del sottoinsieme del dataset è definita dal parametro max_samples parameter altrimenti ogni albero viene costruito usando tutto il dataset.\n",
    "\n",
    "L'accuratezza migliore è ottenuta con il modello BernoulliNB ( 88.89 %). <br>\n",
    "\n",
    "La sua confusion matrix è la seguente: <br>\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; precision &emsp;&emsp;recall &emsp;f1-score &emsp; support\n",
    "\n",
    "          -1       0.99      0.26      0.41       927\n",
    "           1       0.88      1.00      0.94      5258\n",
    "\n",
    "    accuracy                           0.89      6185   \n",
    "    macro avg      0.94      0.63      0.68      6185\n",
    "    weighted avg   0.90      0.89      0.86      6185\n",
    "\n",
    "\n",
    "Nella confusion matrix sono presenti valori di:\n",
    "\n",
    "- Accuratezza: percentuale di risposte classificate correttamente (0.89)\n",
    "\n",
    "- Precision: percentuale di risposte classificate come positive/negative che sono realmente positive/negative. 0.99 per le negative e 0.88 per le positive.\n",
    "\n",
    "- Recall: percentuale di risposte positive/negative che sono state classificate come positive/negative. 0.26 per le negative (percentuale bassa), 1.0 per le positive.\n",
    "\n",
    "- f1-score: la media tra precision and recall. Tiene in considerazione sia i falsi positivi che i falsi negativi. 0.41 per le risposte negative e 0.94 per le positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples number 30925\n",
      "good samples number 26100\n",
      "bad samples number 4825\n",
      "selected samples number for each class 4825\n",
      "selected features number 113000\n",
      "\n",
      "multinomial bayes: 85.01 %\n",
      "BernoulliNB: 88.89 %\n",
      "complement bayes: 76.8 %\n",
      "RandomForestClassifier: 85.01 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.26      0.41       927\n",
      "           1       0.88      1.00      0.94      5258\n",
      "\n",
      "    accuracy                           0.89      6185\n",
      "   macro avg       0.94      0.63      0.68      6185\n",
      "weighted avg       0.90      0.89      0.86      6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def show_performance_data(Y_test, Y_pred, model_name):\n",
    "  print(classification_report(Y_test, Y_pred, target_names=['-1','1']))\n",
    "  tmp_result = classification_report(Y_test, Y_pred, target_names=['-1','1'], output_dict=True)\n",
    "  return tmp_result\n",
    "\n",
    "def train_test_classificators_and_get_the_best_one(classificators, X_train, X_test, y_train, y_test):\n",
    "    best_accuracy = -1\n",
    "\n",
    "    for clf, name in classificators:\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = round(clf.score(X_test, y_test) * 100, 2)\n",
    "        \n",
    "        print(name + \": \" + str(score) + \" %\")\n",
    "\n",
    "        if best_accuracy < score:\n",
    "            best_accuracy = score\n",
    "            best_clf = clf\n",
    "            best_clf_name = name\n",
    "    \n",
    "    return best_clf, best_clf_name\n",
    "\n",
    "\n",
    "def get_X_and_y_after_features_extraction(samples, ngram_range):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range) #creato oggetto TfidfVectorizer passando le dimensioni del n-gramma\n",
    "    \n",
    "    X = vectorizer.fit_transform(samples[\"text\"].astype(str).tolist())# #fit_transform apprende il vocabolario e restituisce le risposte in una matrice \n",
    "    y = samples[\"label\"].tolist()\n",
    "    \n",
    "    return X, y, vectorizer\n",
    "\n",
    "\n",
    "def get_X_after_feature_selection(X, y, best_feature_number):\n",
    "    np.seterr(invalid='ignore')\n",
    "    \n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=best_feature_number) #selezione delle feature più importanti calcolando lo score con la funzione f_classif\n",
    "                                        #f_classif prenderà due array X e y e ritornerà un array con gli score associati a ogni feature.\n",
    "    selected_feature = feature_selector.fit_transform(X, y) #X viene ridotto alle feature selezionate \n",
    "    \n",
    "    print(\"selected features number \" + str(best_feature_number) + \"\\n\")\n",
    "    return selected_feature, feature_selector\n",
    "\n",
    "\n",
    "def get_label(samples):\n",
    "    return samples[0]\n",
    "\n",
    "\n",
    "def get_balanced_dataframe(samples):\n",
    "    samples = samples.values.tolist() #samples trasformato in una lista\n",
    "    \n",
    "    shuffle(samples) #prende una lista e cambia l'ordine degli elementi\n",
    "    \n",
    "    good_samples = [sample for sample in samples if get_label(sample) == 1] #calcolo del numero di risposte positive\n",
    "    bad_samples = [sample for sample in samples if get_label(sample) == -1] #calcolo numero di risposte negative\n",
    "\n",
    "    print(\"total samples number \" + str(len(samples)))\n",
    "    print(\"good samples number \" + str(len(good_samples)))\n",
    "    print(\"bad samples number \" + str(len(bad_samples)))\n",
    "\n",
    "    balanced_number_of_samples = min(len(good_samples), len(bad_samples)) \n",
    "   \n",
    "    print(\"selected samples number for each class \" + str(balanced_number_of_samples)) \n",
    "    \n",
    "    balanced_samples = good_samples[:balanced_number_of_samples] + bad_samples[:balanced_number_of_samples] #prendo lo stesso numero di risposte positive e negative\n",
    "\n",
    "    balanced_samples = pd.DataFrame(balanced_samples, columns=[\"label\", \"text\"])\n",
    "    \n",
    "    return pd.DataFrame(samples, columns=[\"label\", \"text\"]) #restituisco dataset per addestramento\n",
    "\n",
    "\n",
    "###########################################################\n",
    "#                                               \n",
    "#                           | MAIN |\n",
    "#                                                 \n",
    "###########################################################\n",
    "\n",
    "test_size = 0.2 #dimensione del dataset di testing\n",
    "ngram_range = (2, 4) #2,4 #dimensione del n-gramma\n",
    "best_feature_number = 113000 #113000 #100000 #118000 numero di feature selezionate\n",
    "\n",
    "# 1° bilanciamento tra numero di risposte negative e positive e shuffle delle risposte\n",
    "samples_1 = get_balanced_dataframe(samples)\n",
    "\n",
    "# 2° feature extraction\n",
    "X, y, vectorizer = get_X_and_y_after_features_extraction(samples_1, ngram_range)\n",
    "\n",
    "# 3° prendiamo solo determinate feature \n",
    "X, feature_selector = get_X_after_feature_selection(X, y, best_feature_number)\n",
    "\n",
    "# 4° divisione tra training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "\n",
    "classificators = [\n",
    "                    (MultinomialNB(), \"multinomial bayes\"),\n",
    "                    (BernoulliNB(), \"BernoulliNB\"),                       \n",
    "                    (ComplementNB(), \"complement bayes\"),\n",
    "                    (RandomForestClassifier(n_estimators=70, oob_score=True, n_jobs=-1, random_state=101, min_samples_leaf=30), \"RandomForestClassifier\"), # lento\n",
    "                ]\n",
    "\n",
    "# 6° prende la lista dei classificatori e prende il migliore \n",
    "best_clf, best_clf_name = train_test_classificators_and_get_the_best_one(classificators, X_train, X_test, y_train, y_test)\n",
    "\n",
    "Y_pred=best_clf.predict(X_test)\n",
    "ris=show_performance_data(y_test, Y_pred, best_clf_name) #per mostrare la matrice di confusione del modello migliore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora vengono uniti in un unico dataframe 'domande' tutti i dataframe che contengono le risposte e i loro score. <br>\n",
    "Per ogni cliente si può calcolare il suo score di soddisfazione. <br>\n",
    "Viene prima effettuata una groupby su l'id del cliente e poi calcolata la media sulla colonna 'SCORE'. Il risultato è memorizzato nella variabile 'score_utente'. <br>\n",
    "\n",
    "Per individuare i tre clienti più soddisfatti viene ordinato il dataframe 'score_utente' in ordine descrescente rispetto allo score. Molti clienti risultano avere lo score massimo (+1), quindi si prende in considerazione anche quanti questionari hanno compilato. I clienti più soddisfatti risultano essere 20200569, 23007684, 13076375. <br>\n",
    "\n",
    "Con gli stessi criteri vengono trovati i clienti più insoddisfatti, cioè quelli che hanno score -1 e hanno compilato il maggior numero di questionari. Questi sono 7117139, 22996262, 11478292.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID_CLIENTE  SCORE  N_QUESTIONARI\n",
      "71092    20200569    1.0             71\n",
      "89281    23007684    1.0             55\n",
      "47081    13076375    1.0             45\n",
      "       ID_CLIENTE  SCORE  N_QUESTIONARI\n",
      "5692      7117139   -1.0             18\n",
      "39236    11478292   -1.0             10\n",
      "89011    22996262   -1.0             10\n"
     ]
    }
   ],
   "source": [
    "#fare merge verticale di tutte le domande con i loro score\n",
    "#unire i due gruppi di domande\n",
    "domande=pd.merge(left=chiuse, right=chiuse_multiple,how='outer')\n",
    "domande=pd.merge(left=domande, right=aperte,how='outer')\n",
    "\n",
    "#groupby su ID_CLIENTE e poi calcolata la media su 'SCORE'\n",
    "score_utente=domande.groupby(['ID_CLIENTE'])['SCORE'].mean()\n",
    "score_utente=score_utente.reset_index() #resettati gli indici\n",
    "score_utente.columns=['ID_CLIENTE','SCORE']\n",
    "score_utente['SCORE']=score_utente['SCORE'].round(2) # arrotondamento degli score a due cifre dopo la virgola\n",
    "\n",
    "utente_ndomande=domande.groupby(['ID_CLIENTE']).count()['ID_QUESTIONARIO'] #contare quanti questionari per ogni cliente\n",
    "utente_ndomande=utente_ndomande.reset_index()\n",
    "utente_ndomande.columns=['ID_CLIENTE', 'N_QUESTIONARI'] #rinominiamo le colonne\n",
    "utenti_ordinati=pd.merge(left=score_utente, right=utente_ndomande,how='outer') #associamo a ogni cliente il numero di questionari svolti\n",
    "utenti_ordinati_desc=utenti_ordinati.sort_values(by=['SCORE','N_QUESTIONARI'], ascending=False) #in ordine descrescente di score e n questionari\n",
    "print(utenti_ordinati_desc.head(3))\n",
    "utenti_ordinati_asc=utenti_ordinati.sort_values(by=['SCORE','N_QUESTIONARI'], ascending=[True,False]) #in ordine crescente di score e decrescente di questionari\n",
    "print(utenti_ordinati_asc.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analytics\n",
    "## Importazione dati su Neo4j\n",
    "I dati prodotti devono essere importati in Neo4j, ma prima bisogna produrre dei file csv con i dati strutturati correttamente.  <br>\n",
    "\n",
    "- Viene creato un csv con tutti i clienti che compaiono in dataset2 in modo da avere tutte le informazioni per i nodi Cliente che saranno importati ('clienti_all.csv').\n",
    "\n",
    "- un altro file con gli score associati ai clienti ('score.csv').\n",
    "\n",
    "- un file con i collegamenti. Al dataset2 che contiene i collegamenti vengono aggiunte due colonne che attribuiscono un valore a ciascuna relazione. Questi campi sono necessari per una futura analisi del grafo neo4j. Questi campi vengono presi dal file peso.csv. Il file contiene ogni tipo di relazione a cui è associato un costo e un peso. Il peso rappresenta la forza della relazione, il costo è il costo per attraversare quel tipo di arco del grafo. Le due colonne vengono aggiunte a dataset2 e poi viene creato il file ('dataset_collegamenti.csv').\n",
    "\n",
    "- un file con le filiali. Per l'obiettivo 2 della graph analysis è necessario avere anche i nodi delle filiali. Creiamo un file con l'elenco degli id delle filiali presenti in dataset2 ('filiali.csv').\n",
    "\n",
    "- un file con i collegamenti tra clienti e la loro filiale ('coll_cliente_filiale.csv')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendo le colonne con id cliente, id filiale e codice natura giuridica \n",
    "ID_CLIENTE=dataset2.iloc[:, 0:3] \n",
    "ID_CLIENTE2=dataset2.iloc[:,5:8]\n",
    "ID_CLIENTE.columns=['ID_CLIENTE','COD_NATURA_GIURIDICA','ID_FILIALE'] #rinomino le colonne\n",
    "ID_CLIENTE2.columns=['ID_CLIENTE','COD_NATURA_GIURIDICA','ID_FILIALE'] #rinomino le colonne\n",
    "ID_CLIENTE=ID_CLIENTE.merge(ID_CLIENTE2,how='outer') #merge verticale \n",
    "ID_CLIENTE=ID_CLIENTE.drop_duplicates() #eliminati i clienti duplicati\n",
    "ID_CLIENTE.to_csv('clienti_all.csv',index=False, header=False) # creato file csv con tutti i clienti \n",
    "\n",
    "#DATASET con score\n",
    "lista=list(ID_CLIENTE['ID_CLIENTE']) #prendo la lista degli id dei clienti\n",
    "score_utente=score_utente.loc[score_utente['ID_CLIENTE'].isin(lista)] #prendo gli score (se esistono) di quei clienti \n",
    "score_utente.to_csv('score.csv',index=False) # creato file csv con tutti gli score associati all'id cliente\n",
    "\n",
    "#DATASET collegamenti\n",
    "pesi = pd.read_csv('peso.csv', sep=\",\", header=0,dtype = {\n",
    "    'COD_COLLEGAMENTO': str,                                 \n",
    "    'DESC_COLLEGAMENTO': str,   \n",
    "    'PESO': int,\n",
    "    'COSTO': int }) \n",
    "dataset2_pesi=pd.merge(left=dataset2, right=pesi,how='inner') \n",
    "dataset2_pesi.to_csv('dataset_collegamenti.csv',index=False, header=False) #csv senza index e header\n",
    "\n",
    "#DATASET filiali\n",
    "filiali=ID_CLIENTE['ID_FILIALE'].drop_duplicates() #prendiamo la colonna filiali e eliminiamo i duplicati\n",
    "filiali=filiali.astype(int)\n",
    "filiali.to_csv('filiali.csv',index=False, header=False) # creato file csv con tutte le filiali \n",
    "\n",
    "#DATASET collegamenti clienti-filiali\n",
    "coll_cliente_filiale=ID_CLIENTE.loc[:,['ID_CLIENTE','ID_FILIALE']] #prendiamo le colonne clienti e filiali\n",
    "coll_cliente_filiale.to_csv('coll_cliente_filiale.csv',index=False, header=False) #csv senza index e header"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
